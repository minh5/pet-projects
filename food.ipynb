{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Hello, world!</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import scipy\n",
    "import theano.tensor as tt\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "plotly.tools.set_credentials_file(username=os.environ.get('PLOTLY_USERNAME'), api_key=os.environ.get('PLOTLY_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "After receiving the data, I did a quick cursory look and tried to conduct a series of analyses that I felt would be most beneficial to **(omitted)** given their data. The following questions help framed what I am looking and examining for are:\n",
    "\n",
    "   - What foods are usually paired with each other?\n",
    "   - What relationship do the foods have to each other?\n",
    "   - Is there a seasonality effect on food choices?\n",
    "   \n",
    "The first question looks at combinations of food that are ordered together. Since the transaction ids can have multiple items, it would be beneficial to see what items are bought with each other. This would be helpful if we are trying to upsell certain items or we can use to train employees to make recommendations. \n",
    "\n",
    "The second question looks at the relationship of the food combinations. Now that we know what kind of combinations of food are frequently bought together, what can we infer about their relationship? This would be useful if want to sell certain combinations at certain time or providing special deals for certain food combination.\n",
    "\n",
    "The third question is to look at any temporal effects on our sales. Rather than looking at the combination of food sales being dependent on our ability to market to the customer, it may be due to external factors. Having used to work in multiple restaurants, I know that the weather or time of year can play a huge role in driving sales of certain items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateofpurch</th>\n",
       "      <th>item</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>Greens&amp;Grains</td>\n",
       "      <td>1cb598ac-24ff-4734-ab8d-b4422c467870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>1cb598ac-24ff-4734-ab8d-b4422c467870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>chips</td>\n",
       "      <td>1cb598ac-24ff-4734-ab8d-b4422c467870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>Salad</td>\n",
       "      <td>1cb598ac-24ff-4734-ab8d-b4422c467870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>braised_lamb</td>\n",
       "      <td>1cb598ac-24ff-4734-ab8d-b4422c467870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dateofpurch           item                         transactionid\n",
       "0  2014-04-27  Greens&Grains  1cb598ac-24ff-4734-ab8d-b4422c467870\n",
       "1  2014-04-27        Chicken  1cb598ac-24ff-4734-ab8d-b4422c467870\n",
       "2  2014-04-27          chips  1cb598ac-24ff-4734-ab8d-b4422c467870\n",
       "3  2014-04-27          Salad  1cb598ac-24ff-4734-ab8d-b4422c467870\n",
       "4  2014-04-27   braised_lamb  1cb598ac-24ff-4734-ab8d-b4422c467870"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/food_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "Here I looked at some descriptive statistics. Soon, I saw that there was a date of transaction, so I transformed the column into a `datetime` format so I can do time operations down the road. \n",
    "\n",
    "I was curious to answer certain questions such as \"What are the most common items sold?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chicken          373191\n",
       "Bowl             316073\n",
       "Salad            270926\n",
       "falafel          159859\n",
       "meatballs        104021\n",
       "cookie           100016\n",
       "lamb_sliders      99115\n",
       "Minis             90430\n",
       "Pita              89763\n",
       "Greens&Grains     89508\n",
       "braised_lamb      67842\n",
       "chips             63558\n",
       "braised_beef      51731\n",
       "soup              44982\n",
       "large_drink       39218\n",
       "small_drink       37797\n",
       "Name: item, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date'] = data['dateofpurch'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "data.item.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having queried this, I now wanted to know the number of items sold and unique transactions. I also looked at the standard deviations of the items and unique transaction a day to see the variability, if the standard deviation is high, we can expect the number sales a day not to be consistent and would warrant further investigation with questions such as \"What specific day do we see higher or lower sales?\" or \"What kind of days would skew the sales data?\" However, the standard deviation was pretty small, so I did not investigate that much further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of number of items sold a day: 82.5111116985\n",
      "Standard Deviation of number of unique transactions a day: 24.1223939028\n"
     ]
    }
   ],
   "source": [
    "# number of purchases by day\n",
    "data.dateofpurch.value_counts()\n",
    "stdev_day = np.std(data.dateofpurch.value_counts().values)\n",
    "\n",
    "# number of unique transaction by day\n",
    "grouped = data.groupby(['dateofpurch', 'transactionid']).count().groupby(level='dateofpurch').size()\n",
    "std_dev_trans = np.std(grouped.values)\n",
    "\n",
    "print('Standard Deviation of number of items sold a day:', str(stdev_day))\n",
    "print('Standard Deviation of number of unique transactions a day:', str(std_dev_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_item_counts_by_date(data, item, full_index, date_column, food_column):\n",
    "    sub = data.ix[data[food_column] == item, :]\n",
    "    indx = sub.groupby(date_column).count().index\n",
    "    vals = sub.groupby(date_column).count()[food_column].values\n",
    "    item_dict = dict(zip(indx, vals))\n",
    "    fill_in_dates = list(set(full_index) - set(indx))\n",
    "    for date in fill_in_dates:\n",
    "        item_dict[date] = 0\n",
    "    return item_dict\n",
    "\n",
    "def create_chart_by_items(data, items, date_column='dateofpurch', food_column='item', title='Sales'):\n",
    "    graph = []\n",
    "    for item in items:\n",
    "        test = create_item_counts_by_date(data, item, set(data[date_column]), date_column, food_column)\n",
    "\n",
    "        # Create traces\n",
    "        trace = go.Scatter(\n",
    "            x = sorted(set(data[date_column])),\n",
    "            y = [i[1] for i in sorted(test.items())],\n",
    "            mode = 'lines',\n",
    "            name = item[0].upper() + item[1:]\n",
    "        )\n",
    "        graph.append(trace)\n",
    "\n",
    "    layout = dict(title = title,\n",
    "                  xaxis = dict(title = 'Month'),\n",
    "                  yaxis = dict(title = 'Number of Items Sold'.format(item)),\n",
    "                  )\n",
    "    fig = dict(data=graph, layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at some descriptive statistics, I created a short function that would parse the data and create a chart that visualize the sales by day, since I will be reusing it often during the explanatory analysis phase. Below are plots are the sales of different proteins and food bases by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/382.embed\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at the base items\n",
    "# items = ['Chicken', 'meatballs', 'falafel', 'braised_lamb', 'braised_beef']\n",
    "# fig = create_chart_by_items(data, items, title='Sales by Protein Type')\n",
    "# py.iplot(fig, filename='protein')\n",
    "html = '''\n",
    "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/382.embed\"></iframe>\n",
    "'''\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/380.embed\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# items = ['Salad', 'Greens&Grains', 'Bowl', 'Pita', 'Minis']\n",
    "# fig = create_chart_by_items(data, items, title='Sale by Base Item')\n",
    "# py.iplot(fig, filename='base')\n",
    "html = '''\n",
    "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/380.embed\"></iframe>\n",
    "'''\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs, there are a few patterns that emerges. First off, chicken remains the number one protein above all other protein types. In fact, there are no day from 2013 to 2015 where there were any protein sells more than chicken. Falafel is a distant second followed by meatball, braised lamb, and braised beef.  Second, it appears that Salads and Bowls are the top selling base items, with Bowls generally overselling Salads but the distinction is not as clear, since there are some days salads sell more than bowls. The other base types (pita, minis , and greens and grains) are mixed in together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What foods are usually paired with each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a pretty good idea of the items sold. I started looking at what kind of transactions take place. From a quick count, we see that 75% of all transactions have 2 or 3 items. There is also a small number of people ordering 17 or more items on (perhaps a group meal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     343713\n",
       "3     148570\n",
       "4      73338\n",
       "5      38261\n",
       "6      29566\n",
       "7       9778\n",
       "8       7498\n",
       "9       3673\n",
       "10      1652\n",
       "11       957\n",
       "12       543\n",
       "1        532\n",
       "13       220\n",
       "14       147\n",
       "15        72\n",
       "16        35\n",
       "17        22\n",
       "19         7\n",
       "18         5\n",
       "20         3\n",
       "21         1\n",
       "23         1\n",
       "Name: item, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common items purchases\n",
    "grouped = data.groupby('transactionid').count()\n",
    "grouped['item'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# looing at tranactions where there are 2 or 3 \n",
    "single_indx = grouped.ix[grouped['item'] == 1, :].index.values.tolist()\n",
    "multiple_indx = grouped.ix[grouped['item'].isin([2,3,4]), :].index.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also 500 people who ordered only 1 item, which after a look quick, turns out to just be pitas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiple = data.ix[data['transactionid'].isin(multiple_indx), :]\n",
    "def collapse_food_by_id(data, new_column_name='combo'):\n",
    "    results_dict = {}\n",
    "    for tid in data['transactionid']:\n",
    "        results_dict[tid] = []\n",
    "    for i, row in data.iterrows():\n",
    "        results_dict[row['transactionid']] = sorted(results_dict[row['transactionid']] + [row['item']])\n",
    "    results_dict = {k: (', ').join(v) for k, v in results_dict.items()}\n",
    "    df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    df.columns = [new_column_name]\n",
    "    df['counts'] = df[new_column_name].apply(lambda x: x.count(',') + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pita    532\n",
       "Name: item, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ix[data['transactionid'].isin(single_indx), 'item'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next since a transaction can have multiple items associated with it, I must find a way to group the items together. To do this, I take each transaction and create a dictionary with the transaction id as the key and all the items in that transaction as the value. Then after creating the dictionary, I joined the list of items after sorting it (to make sure `[\"Bowl\", \"Chicken\"]` is the same `[\"Chicken\", \"Bowl\"]`) to make a string representation of the transaction. After that, you can simply transform a dictionary into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I can look at the most popular items sold. It turns out that the most popular item is a Chicken bowl, which makes sense because the most popular protein is chicken and the most popular base items are either the bowl or salad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bowl, Chicken             71236\n",
       "Chicken, Salad            49540\n",
       "Salad, falafel            41733\n",
       "Chicken, Greens&Grains    28352\n",
       "Bowl, falafel             24627\n",
       "Bowl, meatballs           12666\n",
       "Chicken, Pita             12107\n",
       "Salad, meatballs          10772\n",
       "Bowl, Chicken, cookie     10127\n",
       "Pita, meatballs            9450\n",
       "Name: combo, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = collapse_food_by_id(multiple)\n",
    "df.combo.value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this process, I have noticed is that the `Bowl, Chicken` is actually one item. Originally, I looked at these two as separate items. From this, we can see that if the transaction has two items, it is actually one item. The count of two represents the base and the protein as one item, or an entree. So below, we can see the most popular entree for transactions where a customer only bought an entree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bowl, Chicken             71236\n",
       "Chicken, Salad            49540\n",
       "Salad, falafel            41733\n",
       "Chicken, Greens&Grains    28352\n",
       "Bowl, falafel             24627\n",
       "Bowl, meatballs           12666\n",
       "Chicken, Pita             12107\n",
       "Salad, meatballs          10772\n",
       "Pita, meatballs            9450\n",
       "Minis, meatballs           9231\n",
       "Name: combo, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[df['counts'] == 2, :]['combo'].value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/384.embed\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged = pd.merge(df, data.ix[:, ['transactionid', 'date']], left_index=True, right_on='transactionid')\n",
    "items = merged.combo.value_counts().index.values.tolist()[0:5]\n",
    "fig2 = create_chart_by_items(merged, items, date_column='date', food_column='combo', title='Sales of Combinations')\n",
    "py.iplot(fig2, filename='combos')\n",
    "html = '''\n",
    "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/384.embed\"></iframe>\n",
    "'''\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there a correlation between sales of certain items?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the counts of the sales of entrees are kind of muddled. I would want to examine the relationship between different entrees. For instance, on days that chicken bowl sales are high, does that mean sales of chicken salads are low? Do people make a trade off between falafel and chicken bowls? The purpose of this is that we can focus on certain items and use it to predict sales. If we know that on certain days, salads are sold more, we can focus on stocking inventory of salads on those days.\n",
    "\n",
    "To do this, I simply ran a quick Pearson's Correlation between the counts of certain items. The Pearson's R statistic gives a number between -1 and 1. Values closer to -1 means an inverse relationship, an increase in one item means a decrease in the other, and values closer to 1 means a direct relationship, where an increase in one item means an increase in the other item.\n",
    "\n",
    "For instance, I looked at the correlation between the sales of Chicken bowl and their salad and Greens&Grains counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between Bowl and Salad:  -0.0479223236549\n",
      "correlation between Bowl and Greens&Grains:  -0.0310560640055\n"
     ]
    }
   ],
   "source": [
    "bowl_sales_by_day = merged.ix[merged['combo'] == 'Bowl, Chicken', :].groupby('date').count()['combo'].values.tolist()\n",
    "salad_sales_by_day = merged.ix[merged['combo'] == 'Chicken, Salad', :].groupby('date').count()['combo'].values.tolist()\n",
    "corr = scipy.stats.pearsonr(bowl_sales_by_day, salad_sales_by_day)[0]\n",
    "print('correlation between Bowl and Salad: ', str(corr))\n",
    "\n",
    "bowl_sales_by_day = merged.ix[merged['combo'] == 'Bowl, Chicken', :].groupby('date').count()['combo'].values.tolist()\n",
    "salad_sales_by_day = merged.ix[merged['combo'] == 'Chicken, Greens&Grains', :].groupby('date').count()['combo'].values.tolist()\n",
    "corr = scipy.stats.pearsonr(bowl_sales_by_day, salad_sales_by_day)[0]\n",
    "print('correlation between Bowl and Greens&Grains: ', str(corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can see there is a just a slight *negative* correlation between the different chicken items. The strength of the correlation is a bit weaker between the bowls and the greens&grains than the bowls and salad. From here, it looks like there is a bit of a trade off between sales of chicken bowls and the other chicken-based entree. Although it is important to keep in mind that correlations is not causation and that we would have to do more tests to test of causality.\n",
    "\n",
    "However, I moved onto more questions about the data that may be more useful. Given that there are transactions of more than one entrees, I'd like to understand who are the people bought more than just the entree. There are two categories of this: customers who buy multiple entrees and customers who add side items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are people buying when it's more than one meal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People who purchase between one to two entrees make up the majority of transactions. While more customers bought single entrees, it may be useful to figure out purchasing patterns for transactions with more than one entree. For instance, if we know that people buy the same base and entrees, we could offer certain buy one, get one (BOGO) deals. Or if we wanted to attract more customers, we could entice them to join a current **(omitted)** customer. These behavior patterns could have postive business implications.\n",
    "\n",
    "To figure this out, I just compared the counts of the items to the unique count of items in a transaction. The first output below shows transaction that are composed of different food bases and proteins, while the second one, it appears that they order two exact same entree combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>counts</th>\n",
       "      <th>transactionid</th>\n",
       "      <th>date</th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244295</th>\n",
       "      <td>Chicken, Greens&amp;Grains, Minis, braised_lamb</td>\n",
       "      <td>4</td>\n",
       "      <td>e50e99d2-0d1b-4aa1-884c-3823c4acfa9f</td>\n",
       "      <td>2013-04-25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244296</th>\n",
       "      <td>Chicken, Greens&amp;Grains, Minis, braised_lamb</td>\n",
       "      <td>4</td>\n",
       "      <td>e50e99d2-0d1b-4aa1-884c-3823c4acfa9f</td>\n",
       "      <td>2013-04-25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244297</th>\n",
       "      <td>Chicken, Greens&amp;Grains, Minis, braised_lamb</td>\n",
       "      <td>4</td>\n",
       "      <td>e50e99d2-0d1b-4aa1-884c-3823c4acfa9f</td>\n",
       "      <td>2013-04-25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244298</th>\n",
       "      <td>Chicken, Greens&amp;Grains, Minis, braised_lamb</td>\n",
       "      <td>4</td>\n",
       "      <td>e50e99d2-0d1b-4aa1-884c-3823c4acfa9f</td>\n",
       "      <td>2013-04-25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952838</th>\n",
       "      <td>Bowl, Chicken, Minis, braised_lamb</td>\n",
       "      <td>4</td>\n",
       "      <td>4f611e17-0df6-49f3-8160-214a512a25d5</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               combo  counts  \\\n",
       "244295   Chicken, Greens&Grains, Minis, braised_lamb       4   \n",
       "244296   Chicken, Greens&Grains, Minis, braised_lamb       4   \n",
       "244297   Chicken, Greens&Grains, Minis, braised_lamb       4   \n",
       "244298   Chicken, Greens&Grains, Minis, braised_lamb       4   \n",
       "1952838           Bowl, Chicken, Minis, braised_lamb       4   \n",
       "\n",
       "                                transactionid       date  nunique  \n",
       "244295   e50e99d2-0d1b-4aa1-884c-3823c4acfa9f 2013-04-25        4  \n",
       "244296   e50e99d2-0d1b-4aa1-884c-3823c4acfa9f 2013-04-25        4  \n",
       "244297   e50e99d2-0d1b-4aa1-884c-3823c4acfa9f 2013-04-25        4  \n",
       "244298   e50e99d2-0d1b-4aa1-884c-3823c4acfa9f 2013-04-25        4  \n",
       "1952838  4f611e17-0df6-49f3-8160-214a512a25d5 2013-06-26        4  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['nunique'] = merged['combo'].apply(lambda x: len(set(x.replace(' ', '').split(','))))\n",
    "merged.ix[((merged['counts'] == 4) & (merged['nunique'] == 4)), :][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>counts</th>\n",
       "      <th>transactionid</th>\n",
       "      <th>date</th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727890</th>\n",
       "      <td>Bowl, Bowl, Chicken, Chicken</td>\n",
       "      <td>4</td>\n",
       "      <td>033e2626-f073-4824-88c9-3f0f1001074d</td>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727891</th>\n",
       "      <td>Bowl, Bowl, Chicken, Chicken</td>\n",
       "      <td>4</td>\n",
       "      <td>033e2626-f073-4824-88c9-3f0f1001074d</td>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727892</th>\n",
       "      <td>Bowl, Bowl, Chicken, Chicken</td>\n",
       "      <td>4</td>\n",
       "      <td>033e2626-f073-4824-88c9-3f0f1001074d</td>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727893</th>\n",
       "      <td>Bowl, Bowl, Chicken, Chicken</td>\n",
       "      <td>4</td>\n",
       "      <td>033e2626-f073-4824-88c9-3f0f1001074d</td>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285480</th>\n",
       "      <td>Bowl, Bowl, falafel, falafel</td>\n",
       "      <td>4</td>\n",
       "      <td>dc48a646-0a52-4c59-97fd-11a275ea3d7c</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               combo  counts  \\\n",
       "727890  Bowl, Bowl, Chicken, Chicken       4   \n",
       "727891  Bowl, Bowl, Chicken, Chicken       4   \n",
       "727892  Bowl, Bowl, Chicken, Chicken       4   \n",
       "727893  Bowl, Bowl, Chicken, Chicken       4   \n",
       "285480  Bowl, Bowl, falafel, falafel       4   \n",
       "\n",
       "                               transactionid       date  nunique  \n",
       "727890  033e2626-f073-4824-88c9-3f0f1001074d 2014-02-03        2  \n",
       "727891  033e2626-f073-4824-88c9-3f0f1001074d 2014-02-03        2  \n",
       "727892  033e2626-f073-4824-88c9-3f0f1001074d 2014-02-03        2  \n",
       "727893  033e2626-f073-4824-88c9-3f0f1001074d 2014-02-03        2  \n",
       "285480  dc48a646-0a52-4c59-97fd-11a275ea3d7c 2015-01-14        2  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.ix[((merged['counts'] == 4) & (merged['nunique'] == 2)), :][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the cross tab of the number of items and the unique number of items in a transaction. We see that there is a sizeable share of people who purchase the same entree combination, around 30%. We can use this information to attract new customers or entice current customers to frequent **(omitted)** more often with special offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nunique</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>687346</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>445662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>98836</td>\n",
       "      <td>80788</td>\n",
       "      <td>113724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nunique   1       2       3       4\n",
       "counts                             \n",
       "2        80  687346       0       0\n",
       "3         6      42  445662       0\n",
       "4         4   98836   80788  113724"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(merged['counts'], merged['nunique'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How often do people add side items?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other end of the spectrum, the people who ordered more than one entree are the ones who had add ons: drinks, cookies, or chips. To figure this out, I created a dummy variable that denotes a 1 if the transaction had an add on and 0 if there are no add ons. Here, we can take a quick look at the most frequent transaction with an add on.\n",
    "\n",
    "Again, it is no surprise that the most popular item, chicken bowl, has an add on as well. However, it is surprising that lamb sliders show up more often. It could be that lamb sliders are considered an add on (I did not consider them as an add on when creating the variable) or that people are more likely to purchase add ons when buying lamb sliders. Furthermore, it is important to note that falafel and meatball protein choices are not in the top ten transaction with add ons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bowl, Chicken, cookie             30381\n",
       "Chicken, Salad, cookie            20955\n",
       "Bowl, Chicken, soup               13539\n",
       "Bowl, chips, lamb_sliders         13377\n",
       "Chicken, Greens&Grains, cookie    12087\n",
       "Salad, chips, lamb_sliders        11595\n",
       "Bowl, braised_lamb, chips         10932\n",
       "Chicken, Salad, soup               9720\n",
       "Pita, chips, lamb_sliders          9618\n",
       "Bowl, braised_lamb, cookie         8127\n",
       "Name: combo, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_ons = ['chips', 'cookie', 'large_drink', 'small_drink', 'soup']\n",
    "merged['add_ons'] = merged['combo'].apply(lambda x: 1 if any([a in x for a in add_ons]) else 0)\n",
    "merged.ix[merged['add_ons'] == 1, :]['combo'].value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after creating the dummy variable and checking the counts, I move onto visualizing the counts of add ons over the years. During my first iteration of creating the graph, it was far too noisy to make any sense. I created a smoothing function by taking the moving average of thirty days. This will help reduce the noise by taking the average of the specified time period rather than the pure counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the graph of the counts of add ons over time. We can see that the moving averages (orange) is much smoother than the raw counts (blue). From here, it doesn't look like there is much of a change, although the averages towards the end of this year seems to be dropping down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addons = merged.ix[merged['add_ons'] == 1, :].groupby('date').count()['add_ons']\n",
    "rolling = pd.Series(addons)\n",
    "rolling = rolling.rolling(window=30).mean()\n",
    "trace = go.Scatter(\n",
    "    x = addons.index.tolist(),\n",
    "    y = addons.values.tolist(),\n",
    "    mode = 'lines',\n",
    "    name = 'Add Ons'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = addons.index.tolist(),\n",
    "    y = rolling.values.tolist(),\n",
    "    mode = 'lines',\n",
    "    name = 'Add Ons Smoothed'\n",
    ")\n",
    "layout = dict(title = 'Addons Over Time',\n",
    "              xaxis = dict(title='Month'),\n",
    "              yaxis = dict(title='Number of Addons Sold, Smoothed'),\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/316.embed\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig = dict(data=[trace, trace1], layout=layout)\n",
    "# py.iplot(fig, filename='line-mode')\n",
    "html = '''\n",
    "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/316.embed\"></iframe>\n",
    "'''\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the seasonality affect sales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first job was at Auntie Anne's and then I spent most of college waiting tables to make money. I know first-hand that the weather can affect sales. I knew that lemonade and regular pretzels sales will skyrocket during the Summer and that cinnamon pretzels are popular during the Winter.\n",
    "\n",
    "To test this, I used a Bayesian approach, which was inspired by [this book](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/). The idea of Bayesian perspective is that the data is fixed and the parameters of the distribution need to be determined, while the Frequentist approach assumed the parameter of a distribution to be fixed and the data is random. For instance, most hypothesis testing would assume the data is drawn from a certain distribution and would test results to determine if the data presented is from that same underlying distribution. In this case, the counts of the items sold can be modeled from a Poisson distribution, which takes in a parameter, alpha, which represents the expected count. To determine the paramter, I made another assumption: that there is a point where the distribution that represents the sale of a certain item changes. In this instance, I assumed the cut off point to be summer and winter (because, let's be honest, those are the only two seasons we get in DC). \n",
    "\n",
    "First, I separated the data set by the fiscal year, 2013, 2014, and 2015. Then, I separated the data set into only salad sales, since I assumed that salads have seasonal components. For instance, salads might be more popular in the summer and bowls could be more popular in the winter (when people aren't so conscious about their bodies).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy_13 = merged.ix[merged['date'] < datetime.datetime(2014, 1, 1), :]\n",
    "fy_14 = merged.ix[((merged['date'] >= datetime.datetime(2014, 1, 1)) & (merged['date'] < datetime.datetime(2015, 1, 1))), :]\n",
    "fy_15 = merged.ix[merged['date'] >= datetime.datetime(2014, 1, 1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fy_13_salad = fy_13.ix[fy_13['combo'].str.contains('Salad') , :].groupby('date').count()['combo']\n",
    "fy_14_salad = fy_14.ix[fy_14['combo'].str.contains('Salad') , :].groupby('date').count()['combo']\n",
    "fy_15_salad = fy_15.ix[fy_15['combo'].str.contains('Salad') , :].groupby('date').count()['combo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then created a probabilistic model that tries to determine the where there are points (switch points) in the data that are different. This is represented by the variable, tau, which is drawn from a discrete uniform distribution. This is because I have no assumption of where the switch point is (because DC weather is so variable, my guess is as good as anybody of when does Winter ends and Summer begins). And before and after this switch point, the count data can be modeled by the Poisson distribution, which as I mentioned earlier, which has the parameter, lambda. In this model, lambda is drawn from an exponential distribution, which takes in positive numbers. This model will iterate over and assign different lambda values depending on which season it is on. After this, it will create a \"posterior\" distribution, which represent the distribution of the data after determining the switch points and assigning the lambda parameters. Then we can employ Markov Chain Monte Carlo to draw sample from this distribution so we can have an idea of what the sales look like. I wrote a quick function below and used salad sales from 2013 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_seasonality_chart(data, num_samples=10000,\n",
    "                             dist_title='Posterior Distribution',\n",
    "                             days_title='Distribution of Sales Change Days'):\n",
    "    with pm.Model() as model:\n",
    "        alpha = 1.0/data.mean()\n",
    "        lambda_1 = pm.Exponential(\"lambda_1\", alpha)\n",
    "        lambda_2 = pm.Exponential(\"lambda_2\", alpha)\n",
    "        tau = pm.DiscreteUniform(\"tau\", lower=0, upper=len(data) - 1)\n",
    "        idx = np.arange(len(data))\n",
    "        lambda_ = pm.math.switch(tau >= idx, lambda_1, lambda_2)\n",
    "        observation = pm.Poisson(\"obs\", lambda_, observed=data)\n",
    "        step = pm.Metropolis()\n",
    "        trace = pm.sample(num_samples, tune=5000, step=step)\n",
    "\n",
    "    lambda_1_samples = trace['lambda_1']\n",
    "    lambda_2_samples = trace['lambda_2']\n",
    "    tau_samples = trace['tau']\n",
    "\n",
    "    trace1 = go.Histogram(\n",
    "        x=lambda_1_samples,\n",
    "        opacity=0.75,\n",
    "        name='Winter'\n",
    "    )\n",
    "    trace2 = go.Histogram(\n",
    "        x=lambda_2_samples,\n",
    "        opacity=0.75,\n",
    "        name='Summer'\n",
    "    )\n",
    "\n",
    "    graph_data = [trace1, trace2]\n",
    "    layout = go.Layout(barmode='overlay', title=dist_title)\n",
    "    fig = go.Figure(data=graph_data, layout=layout)\n",
    "    \n",
    "    trace_days = go.Histogram(\n",
    "    x=tau_samples,\n",
    "    opacity=0.75,\n",
    "    name='Days'\n",
    "    )\n",
    "    days_data = [trace_days]\n",
    "    layout = go.Layout(barmode='overlay', title=days_title)\n",
    "    days_fig = go.Figure(data=days_data, layout=layout)\n",
    "\n",
    "    return fig, days_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/387.embed\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig1, fig2 = create_seasonality_chart(fy_13_salad, dist_title='Posterior Distribution of 2013 Salads Sales')\n",
    "# py.iplot(fig1, filename='fy_13_salad')\n",
    "html = '''\n",
    "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/387.embed\"></iframe>\n",
    "'''\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"900\" height=\"400\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/389.embed\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# py.iplot(fig2, filename='fy_13_salad_days')\n",
    "html = '''\n",
    "<iframe width=\"900\" height=\"400\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/389.embed\"></iframe>\n",
    "'''\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data, we can see two distinct distribution. We can see that average salad sale in the Winter is around 440 while it looks to be around 450, which seems to be higher. And we can look at the second plot, we see where the switch point occurs, where we see that the salad sales changed, around 177 days (6 months), which seems a reasonable time for summer to begin in DC. \n",
    "\n",
    "Now the data is not always this clear cut. We can look at the salad sales data for 2014 and 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/391.embed\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig1, fig2 = create_seasonality_chart(fy_14_salad, dist_title='Posterior Distribution of 2014 Salads')\n",
    "# py.iplot(fig1, filename='fy_14_salad_days')\n",
    "html = '''\n",
    "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/391.embed\"></iframe>\n",
    "'''\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/393.embed\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig1, fig2 = create_seasonality_chart(fy_15_salad, dist_title='Posterior Distribution of 2015 Salads')\n",
    "# py.iplot(fig1, filename='fy_15_salad_days')\n",
    "html = '''\n",
    "<iframe width=\"900\" height=\"600\" frameborder=\"0\" scrolling=\"no\" src=\"//plot.ly/~minh5/393.embed\"></iframe>\n",
    "'''\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two distributions are much \"fatter\" than the 2013, which means that the level of uncertainty is much higher. In 2014, we see that the two distribution overlaps a bit more than 2013. In 2015, we see an odd outcome, the distribution for the Summer is engulfed inside the Winter sales. The Winter sales are very wide, which means that model is unable to determine the lambda for the salad sales. Unlike the 2013 salad sales, the model is unable to determine any seasonality for the sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "For this exercise, my main concern is to just understand the data, come up with hypothesis, and think about how I would go about in solving it. The questions I tried to test were:\n",
    "  - What foods are usually paired with each other?\n",
    "  - What relationship do the foods have to each other?\n",
    "  - Is there a seasonality effect on food choices?\n",
    "  \n",
    "I found out that the food item that is the most sold are the Chicken salad and the chicken bowl. I found out that chicken bowl is **slightly** correlated with the chicken salad and greens and grains. Along the way, I explored two more questions:\n",
    "  - What about transactions that have more than one entree?\n",
    "  - What about transactions with add ons?\n",
    "  \n",
    "During this, I discovered out that there is a sizeable number of customers who buy the same entrees, which could be a useful business straetegy. Regarding add ons, we see that there is not much of a change in the number of add ons sold over the years. Finally, when looking at seasonality, I used a Bayesian method to determine if the distribution between the two seasons were different. I showed that the distribution for salad sales in 2013 have a higher chance of being different.\n",
    "These approaches can be reused over and over to test on different aspects of the data that I did not have a chance to explore. Ideally, if I had the time, I would examine every single food base and protein to mine for insights that **(omitted)** could use to gain new customers and retain current ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
